{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e525450-bff1-4e19-9498-121fd161403a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123d0a4e-28da-48e6-a0a7-3d68c7183ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Streamlit app saved as test_code2.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import subprocess\n",
    "#import webbrowser\n",
    "import time\n",
    "\n",
    "# Streamlit app code\n",
    "test_code2='''\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Streamlit App Configuration\n",
    "st.set_page_config(page_title=\"Data Pipeline Dashboard\", layout=\"wide\")\n",
    "st.title(\"ðŸ“Š Data Pipeline Dashboard\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: Load Data\n",
    "# -------------------------------\n",
    "source_type = st.selectbox(\"Select data source type\", [\"CSV\", \"Excel\", \"JSON\", \"TSV\", \"API\", \"SQL Database\", \"Cloud Storage\", \"Web Scraping\"])\n",
    "\n",
    "def load_data():\n",
    "    if source_type in [\"CSV\", \"Excel\", \"JSON\", \"TSV\"]:\n",
    "        file = st.file_uploader(f\"Upload your {source_type} file\", type=[\"csv\", \"xlsx\", \"json\", \"tsv\"])\n",
    "        if file is not None:\n",
    "            if source_type == \"CSV\":\n",
    "                return pd.read_csv(file)\n",
    "            elif source_type == \"Excel\":\n",
    "                return pd.read_excel(file)\n",
    "            elif source_type == \"JSON\":\n",
    "                return pd.read_json(file)\n",
    "            elif source_type == \"TSV\":\n",
    "                return pd.read_csv(file, sep='\\t')\n",
    "\n",
    "    elif source_type == \"API\":\n",
    "        api_url = st.text_input(\"Enter API URL\")\n",
    "        if api_url:\n",
    "            response = requests.get(api_url)\n",
    "            if response.status_code == 200:\n",
    "                return pd.DataFrame(response.json())\n",
    "            else:\n",
    "                st.error(\"Failed to fetch data from API\")\n",
    "\n",
    "    elif source_type == \"SQL Database\":\n",
    "        st.info(\"This feature requires SQLAlchemy or similar library. To be implemented if needed.\")\n",
    "\n",
    "    elif source_type == \"Cloud Storage\":\n",
    "        st.warning(\"Cloud Storage fetch skipped - please install required SDK like boto3 for AWS.\")\n",
    "\n",
    "    elif source_type == \"Web Scraping\":\n",
    "        st.info(\"Basic scraping logic. Input URL and tag.\")\n",
    "        from bs4 import BeautifulSoup\n",
    "        scrape_url = st.text_input(\"Enter website URL\")\n",
    "        tag = st.text_input(\"Enter HTML tag to scrape\", value=\"p\")\n",
    "        if scrape_url and tag:\n",
    "            page = requests.get(scrape_url)\n",
    "            soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "            data = [element.text for element in soup.find_all(tag)]\n",
    "            return pd.DataFrame(data, columns=[\"Scraped Data\"])\n",
    "    return None\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "if df is not None:\n",
    "    st.success(\"Data Loaded Successfully\")\n",
    "    \n",
    "# -------------------------------\n",
    "# STEP 2: Understand Data\n",
    "# -------------------------------\n",
    "    domain = st.selectbox(\"Which domain does your data belong to?\", [\"Health\", \"Finance\", \"Education\", \"Marketing\", \"Other\"])\n",
    "    st.markdown(\"### Dataset Overview\")\n",
    "\n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    with col1:\n",
    "        st.write(\"**Shape of Data:**\", df.shape)\n",
    "    with col2:\n",
    "        st.write(\"**Column Names:**\", list(df.columns))\n",
    "    with col3:\n",
    "        st.write(\"**Data Types:**\")\n",
    "        st.dataframe(df.dtypes)\n",
    "\n",
    "    # Step 3: Data Cleaning\n",
    "    st.markdown(\"### ðŸ§¹ Data Cleaning\")\n",
    "\n",
    "    if df.duplicated().any():\n",
    "        dup_action = st.selectbox(\"Duplicates found. What would you like to do?\", [\"Drop Duplicates\", \"Retain Duplicates\"])\n",
    "        if dup_action == \"Drop Duplicates\":\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            st.success(\"Duplicates dropped.\")\n",
    "        else:\n",
    "            st.info(\"Duplicates retained.\")\n",
    "    else:\n",
    "        st.info(\"No duplicates found.\")\n",
    "\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        st.write(\"**Missing Values Summary:**\")\n",
    "        st.dataframe(df.isnull().sum())\n",
    "        null_strategy = st.selectbox(\"How do you want to handle missing values?\", [\"Forward Fill\", \"Backward Fill\", \"Drop Rows\"])\n",
    "        if null_strategy == \"Forward Fill\":\n",
    "            df.fillna(method='ffill', inplace=True)\n",
    "            st.success(\"Missing values forward filled.\")\n",
    "        elif null_strategy == \"Backward Fill\":\n",
    "            df.fillna(method='bfill', inplace=True)\n",
    "            st.success(\"Missing values backward filled.\")\n",
    "        else:\n",
    "            df.dropna(inplace=True)\n",
    "            st.success(\"Rows with missing values dropped.\")\n",
    "    else:\n",
    "        st.info(\"No missing values found.\")\n",
    "\n",
    "    # Step 4: Visualization Setup\n",
    "    st.markdown(\"### ðŸ“Š Data Visualization\")\n",
    "\n",
    "    num_charts = st.number_input(\"How many plots would you like to generate?\", min_value=1, step=1)\n",
    "    chart_configs = []\n",
    "\n",
    "    chart_types = [\"Bar\", \"Line\", \"Scatter\", \"Histogram\", \"Box\"]\n",
    "\n",
    "    for i in range(int(num_charts)):\n",
    "        st.markdown(f\"**Chart {i+1} Configuration**\")\n",
    "        chart_type = st.selectbox(f\"Select chart type for Chart {i+1}\", chart_types, key=f\"type_{i}\")\n",
    "        x_axis = st.selectbox(f\"Select x-axis for Chart {i+1}\", [\"None\"] + list(df.columns), key=f\"x_{i}\")\n",
    "        y_axis = st.selectbox(f\"Select y-axis for Chart {i+1}\", [\"None\"] + list(df.columns), key=f\"y_{i}\")\n",
    "        color_axis = st.selectbox(f\"Optional: Select column for color (Chart {i+1})\", [\"None\"] + list(df.columns), key=f\"color_{i}\")\n",
    "        chart_configs.append({\"type\": chart_type, \"x\": x_axis, \"y\": y_axis, \"color\": color_axis})\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"### ðŸ“ˆ Your Charts\")\n",
    "\n",
    "    # Display charts 2 per row\n",
    "    for i in range(0, len(chart_configs), 2):\n",
    "        cols = st.columns(2)\n",
    "        for j in range(2):\n",
    "            if i + j < len(chart_configs):\n",
    "                config = chart_configs[i + j]\n",
    "                with cols[j]:\n",
    "                    if config['x'] != \"None\" and config['y'] != \"None\":\n",
    "                        if config['type'] == \"Bar\":\n",
    "                            fig = px.bar(df, x=config['x'], y=config['y'], color=None if config['color'] == \"None\" else config['color'])\n",
    "                        elif config['type'] == \"Line\":\n",
    "                            fig = px.line(df, x=config['x'], y=config['y'], color=None if config['color'] == \"None\" else config['color'])\n",
    "                        elif config['type'] == \"Scatter\":\n",
    "                            fig = px.scatter(df, x=config['x'], y=config['y'], color=None if config['color'] == \"None\" else config['color'])\n",
    "                        elif config['type'] == \"Histogram\":\n",
    "                            fig = px.histogram(df, x=config['x'], y=config['y'], color=None if config['color'] == \"None\" else config['color'])\n",
    "                        elif config['type'] == \"Box\":\n",
    "                            fig = px.box(df, x=config['x'], y=config['y'], color=None if config['color'] == \"None\" else config['color'])\n",
    "                        st.plotly_chart(fig, use_container_width=True)\n",
    "                    else:\n",
    "                        st.warning(f\"Chart {i+j+1} skipped: x or y axis not specified.\")\n",
    "else:\n",
    "    st.warning(\"Please load your data to proceed.\")\n",
    "'''\n",
    "\n",
    "# Save code to file\n",
    "#with open(\"test_code2.py\", \"w\") as f:\n",
    "with open(\"test_code2.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    f.write(test_code2)\n",
    "\n",
    "print(\"âœ… Streamlit app saved as test_code2.py\")\n",
    "\n",
    "# Run the app\n",
    "process = subprocess.Popen([\"streamlit\", \"run\", \"test_code2.py\"])\n",
    "\n",
    "# Wait for server to start\n",
    "time.sleep(5)\n",
    "\n",
    "# Open in browser\n",
    "#webbrowser.open(\"http://localhost:8501\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14886a7-6d34-473f-a9e8-ae056ff270a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
