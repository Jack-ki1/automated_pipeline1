{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cdb6057-cd70-4665-8aa5-c5e43447248a",
   "metadata": {},
   "source": [
    "## python code below for vs code only"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9eff092f-25e9-4537-8536-a782620c8f87",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "class DataCleaner:\n",
    "    \"\"\"\n",
    "    A reusable class for cleaning datasets in Python.\n",
    "    Handles missing values, duplicates, outliers, datatype fixes,\n",
    "    normalization, and encoding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataframe: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize the cleaner with a pandas DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        dataframe : pd.DataFrame\n",
    "            The raw dataset you want to clean.\n",
    "        \"\"\"\n",
    "        self.df = dataframe.copy()  # Keep original safe\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 1. Basic Information & Inspection\n",
    "    # ----------------------------------------------------------------------\n",
    "    def inspect(self):\n",
    "        \"\"\"Display dataset summary, data types, and missing values.\"\"\"\n",
    "        print(\"---- Data Info ----\")\n",
    "        print(self.df.info())\n",
    "        print(\"\\n---- Missing Values ----\")\n",
    "        print(self.df.isnull().sum())\n",
    "        print(\"\\n---- Preview ----\")\n",
    "        print(self.df.head())\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 2. Handle Missing Values\n",
    "    # ----------------------------------------------------------------------\n",
    "    def handle_missing(self, strategy=\"mean\", fill_values=None):\n",
    "        \"\"\"\n",
    "        Handle missing values in the dataset.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        strategy : str\n",
    "            'mean', 'median', 'mode', or 'custom'\n",
    "        fill_values : dict\n",
    "            Custom dictionary to fill specific columns {col: value}\n",
    "        \"\"\"\n",
    "        if strategy == \"mean\":\n",
    "            # Fill numeric columns with mean\n",
    "            self.df = self.df.fillna(self.df.mean(numeric_only=True))\n",
    "        elif strategy == \"median\":\n",
    "            # Fill numeric columns with median\n",
    "            self.df = self.df.fillna(self.df.median(numeric_only=True))\n",
    "        elif strategy == \"mode\":\n",
    "            # Fill each column with its mode (most frequent value)\n",
    "            for col in self.df.columns:\n",
    "                self.df[col].fillna(self.df[col].mode()[0], inplace=True)\n",
    "        elif strategy == \"custom\" and fill_values:\n",
    "            # Fill based on provided dictionary\n",
    "            self.df = self.df.fillna(fill_values)\n",
    "        else:\n",
    "            # Default: drop rows with missing values\n",
    "            self.df = self.df.dropna()\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 3. Remove Duplicates\n",
    "    # ----------------------------------------------------------------------\n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"Remove duplicate rows.\"\"\"\n",
    "        before = self.df.shape[0]\n",
    "        self.df = self.df.drop_duplicates()\n",
    "        after = self.df.shape[0]\n",
    "        print(f\"Removed {before - after} duplicate rows.\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 4. Fix Data Types\n",
    "    # ----------------------------------------------------------------------\n",
    "    def fix_dtypes(self, dtype_dict=None):\n",
    "        \"\"\"\n",
    "        Convert columns to correct data types.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        dtype_dict : dict\n",
    "            Example: {'date': 'datetime64[ns]', 'id': str, 'category': 'category'}\n",
    "        \"\"\"\n",
    "        if dtype_dict:\n",
    "            for col, dtype in dtype_dict.items():\n",
    "                try:\n",
    "                    if \"datetime\" in str(dtype):\n",
    "                        self.df[col] = pd.to_datetime(self.df[col], errors=\"coerce\")\n",
    "                    else:\n",
    "                        self.df[col] = self.df[col].astype(dtype)\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not convert {col}: {e}\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 5. Handle Outliers\n",
    "    # ----------------------------------------------------------------------\n",
    "    def handle_outliers(self, cols, method=\"IQR\", z_thresh=3):\n",
    "        \"\"\"\n",
    "        Remove outliers using IQR or Z-score.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        cols : list\n",
    "            List of numeric columns to clean\n",
    "        method : str\n",
    "            'IQR' or 'zscore'\n",
    "        z_thresh : int\n",
    "            Z-score threshold (default=3)\n",
    "        \"\"\"\n",
    "        for col in cols:\n",
    "            if method == \"IQR\":\n",
    "                Q1 = self.df[col].quantile(0.25)\n",
    "                Q3 = self.df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                before = self.df.shape[0]\n",
    "                self.df = self.df[(self.df[col] >= Q1 - 1.5 * IQR) &\n",
    "                                  (self.df[col] <= Q3 + 1.5 * IQR)]\n",
    "                after = self.df.shape[0]\n",
    "                print(f\"{col}: Removed {before - after} outliers (IQR).\")\n",
    "            elif method == \"zscore\":\n",
    "                mean = self.df[col].mean()\n",
    "                std = self.df[col].std()\n",
    "                before = self.df.shape[0]\n",
    "                self.df = self.df[(np.abs((self.df[col] - mean) / std) < z_thresh)]\n",
    "                after = self.df.shape[0]\n",
    "                print(f\"{col}: Removed {before - after} outliers (Z-score).\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 6. Standardize Text (for categorical/string columns)\n",
    "    # ----------------------------------------------------------------------\n",
    "    def clean_text(self, cols):\n",
    "        \"\"\"\n",
    "        Standardize text columns (strip spaces, lowercase).\n",
    "        \"\"\"\n",
    "        for col in cols:\n",
    "            self.df[col] = self.df[col].astype(str).str.strip().str.lower()\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 7. Encode Categorical Variables\n",
    "    # ----------------------------------------------------------------------\n",
    "    def encode_categoricals(self, cols, method=\"onehot\"):\n",
    "        \"\"\"\n",
    "        Encode categorical columns.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        cols : list\n",
    "            List of categorical columns\n",
    "        method : str\n",
    "            'onehot' (default) or 'label'\n",
    "        \"\"\"\n",
    "        if method == \"onehot\":\n",
    "            self.df = pd.get_dummies(self.df, columns=cols, drop_first=True)\n",
    "        elif method == \"label\":\n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            le = LabelEncoder()\n",
    "            for col in cols:\n",
    "                self.df[col] = le.fit_transform(self.df[col])\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 8. Scale Numerical Features\n",
    "    # ----------------------------------------------------------------------\n",
    "    def scale_numeric(self, cols, method=\"standard\"):\n",
    "        \"\"\"\n",
    "        Scale numeric columns.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        cols : list\n",
    "            List of numeric columns\n",
    "        method : str\n",
    "            'standard' (z-score normalization) or 'minmax'\n",
    "        \"\"\"\n",
    "        scaler = StandardScaler() if method == \"standard\" else MinMaxScaler()\n",
    "        self.df[cols] = scaler.fit_transform(self.df[cols])\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 9. Save Clean Data\n",
    "    # ----------------------------------------------------------------------\n",
    "    def save(self, filename=\"cleaned_data.csv\"):\n",
    "        \"\"\"Save cleaned DataFrame to CSV.\"\"\"\n",
    "        self.df.to_csv(filename, index=False)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # Utility: Get Clean DataFrame\n",
    "    # ----------------------------------------------------------------------\n",
    "    def get_clean_data(self):\n",
    "        \"\"\"Return the cleaned DataFrame.\"\"\"\n",
    "        return self.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc1e3e5-f64e-4088-9f65-b7ebe2510ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fc89833-a7ec-4a55-a966-28322dd76b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 1. Import Required Libraries\n",
    "# ==============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# ==============================\n",
    "# 2. Define the DataCleaner Class\n",
    "# ==============================\n",
    "class DataCleaner:\n",
    "    \"\"\"\n",
    "    A reusable class for cleaning datasets in Python.\n",
    "    Handles missing values, duplicates, outliers, datatype fixes,\n",
    "    normalization, and encoding.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataframe: pd.DataFrame):\n",
    "        \"\"\"Initialize with a pandas DataFrame\"\"\"\n",
    "        self.df = dataframe.copy()\n",
    "\n",
    "    def inspect(self):\n",
    "        \"\"\"Display dataset summary, datatypes, and missing values\"\"\"\n",
    "        print(\"---- Data Info ----\")\n",
    "        print(self.df.info())\n",
    "        print(\"\\n---- Missing Values ----\")\n",
    "        print(self.df.isnull().sum())\n",
    "        print(\"\\n---- Preview ----\")\n",
    "        display(self.df.head())\n",
    "\n",
    "    def handle_missing(self, strategy=\"mean\", fill_values=None):\n",
    "        \"\"\"Handle missing values (mean, median, mode, custom, or drop)\"\"\"\n",
    "        if strategy == \"mean\":\n",
    "            self.df = self.df.fillna(self.df.mean(numeric_only=True))\n",
    "        elif strategy == \"median\":\n",
    "            self.df = self.df.fillna(self.df.median(numeric_only=True))\n",
    "        elif strategy == \"mode\":\n",
    "            for col in self.df.columns:\n",
    "                self.df[col].fillna(self.df[col].mode()[0], inplace=True)\n",
    "        elif strategy == \"custom\" and fill_values:\n",
    "            self.df = self.df.fillna(fill_values)\n",
    "        else:\n",
    "            self.df = self.df.dropna()\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"Remove duplicate rows\"\"\"\n",
    "        before = self.df.shape[0]\n",
    "        self.df = self.df.drop_duplicates()\n",
    "        after = self.df.shape[0]\n",
    "        print(f\"Removed {before - after} duplicate rows.\")\n",
    "\n",
    "    def fix_dtypes(self, dtype_dict=None):\n",
    "        \"\"\"Convert columns to correct datatypes\"\"\"\n",
    "        if dtype_dict:\n",
    "            for col, dtype in dtype_dict.items():\n",
    "                try:\n",
    "                    if \"datetime\" in str(dtype):\n",
    "                        self.df[col] = pd.to_datetime(self.df[col], errors=\"coerce\")\n",
    "                    else:\n",
    "                        self.df[col] = self.df[col].astype(dtype)\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not convert {col}: {e}\")\n",
    "\n",
    "    def handle_outliers(self, cols, method=\"IQR\", z_thresh=3):\n",
    "        \"\"\"Remove outliers using IQR or Z-score\"\"\"\n",
    "        for col in cols:\n",
    "            if method == \"IQR\":\n",
    "                Q1 = self.df[col].quantile(0.25)\n",
    "                Q3 = self.df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                before = self.df.shape[0]\n",
    "                self.df = self.df[(self.df[col] >= Q1 - 1.5 * IQR) &\n",
    "                                  (self.df[col] <= Q3 + 1.5 * IQR)]\n",
    "                after = self.df.shape[0]\n",
    "                print(f\"{col}: Removed {before - after} outliers (IQR).\")\n",
    "            elif method == \"zscore\":\n",
    "                mean = self.df[col].mean()\n",
    "                std = self.df[col].std()\n",
    "                before = self.df.shape[0]\n",
    "                self.df = self.df[(np.abs((self.df[col] - mean) / std) < z_thresh)]\n",
    "                after = self.df.shape[0]\n",
    "                print(f\"{col}: Removed {before - after} outliers (Z-score).\")\n",
    "\n",
    "    def clean_text(self, cols):\n",
    "        \"\"\"Standardize text columns (strip spaces, lowercase)\"\"\"\n",
    "        for col in cols:\n",
    "            self.df[col] = self.df[col].astype(str).str.strip().str.lower()\n",
    "\n",
    "    def encode_categoricals(self, cols, method=\"onehot\"):\n",
    "        \"\"\"Encode categorical columns (onehot or label encoding)\"\"\"\n",
    "        if method == \"onehot\":\n",
    "            self.df = pd.get_dummies(self.df, columns=cols, drop_first=True)\n",
    "        elif method == \"label\":\n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            le = LabelEncoder()\n",
    "            for col in cols:\n",
    "                self.df[col] = le.fit_transform(self.df[col])\n",
    "\n",
    "    def scale_numeric(self, cols, method=\"standard\"):\n",
    "        \"\"\"Scale numeric features\"\"\"\n",
    "        scaler = StandardScaler() if method == \"standard\" else MinMaxScaler()\n",
    "        self.df[cols] = scaler.fit_transform(self.df[cols])\n",
    "\n",
    "    def save(self, filename=\"cleaned_data.csv\"):\n",
    "        \"\"\"Save cleaned dataset\"\"\"\n",
    "        self.df.to_csv(filename, index=False)\n",
    "        print(f\"Data saved to {filename}\")\n",
    "\n",
    "    def get_clean_data(self):\n",
    "        \"\"\"Return cleaned DataFrame\"\"\"\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ba730a-3885-4d6e-bd74-c7966d7f6150",
   "metadata": {},
   "source": [
    "# ============SAMPLE CASE================\n",
    "\n",
    "### ==============================\n",
    "### 3. Create a Sample Dataset (Raw Data)\n",
    "### ==============================\n",
    "raw_data = {\n",
    "    \"id\": [1, 2, 2, 3, 4, 5, 6, None],\n",
    "    \"name\": [\"Alice \", \"Bob\", \"BOB\", \"Charlie\", None, \"Eve\", \"Frank\", \"Grace\"],\n",
    "    \"age\": [25, 30, 30, 35, None, 45, 200, 28],\n",
    "    \"salary\": [50000, 60000, 60000, None, 80000, 1200000, 70000, 65000],\n",
    "    \"gender\": [\"Female\", \"Male\", \"Male\", \"Male\", \"Female\", None, \"Male\", \"Female\"],\n",
    "    \"date_joined\": [\"2021-01-01\", \"2021-03-15\", \"2021-03-15\", \"2021-06-20\", \n",
    "                    \"2021-09-10\", \"invalid_date\", \"2022-01-01\", \"2022-05-01\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(raw_data)\n",
    "df.head()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. Use DataCleaner Step by Step\n",
    "# ==============================\n",
    "\n",
    "# Initialize cleaner\n",
    "cleaner = DataCleaner(df)\n",
    "\n",
    "# Step 1: Inspect\n",
    "cleaner.inspect()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Step 2: Handle missing values (fill with median for numerics)\n",
    "cleaner.handle_missing(strategy=\"median\")\n",
    "cleaner.inspect()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Step 3: Remove duplicates\n",
    "cleaner.remove_duplicates()\n",
    "cleaner.inspect()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Step 4: Fix datatypes (date column to datetime, id to string)\n",
    "cleaner.fix_dtypes({'date_joined': 'datetime64[ns]', 'id': str})\n",
    "cleaner.inspect()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Step 5: Handle outliers (age, salary columns)\n",
    "cleaner.handle_outliers(cols=[\"age\", \"salary\"], method=\"IQR\")\n",
    "cleaner.inspect()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Step 6: Clean text columns (name, gender)\n",
    "cleaner.clean_text(cols=[\"name\", \"gender\"])\n",
    "cleaner.inspect()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Step 7: Encode categoricals (gender)\n",
    "cleaner.encode_categoricals(cols=[\"gender\"], method=\"onehot\")\n",
    "cleaner.inspect()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Step 8: Scale numeric features (age, salary)\n",
    "cleaner.scale_numeric(cols=[\"age\", \"salary\"], method=\"standard\")\n",
    "cleaner.inspect()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Step 9: Save cleaned dataset\n",
    "cleaner.save(\"client_cleaned_data.csv\")\n",
    "\n",
    "# Get final cleaned DataFrame\n",
    "final_df = cleaner.get_clean_data()\n",
    "final_df.head()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "✅ This notebook shows:\n",
    "\n",
    "* Raw dataset creation\n",
    "* Cleaning **step-by-step with visible outputs**\n",
    "* Final clean dataset saved\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to also include **visualizations (like missing data heatmap, outlier boxplots)** in this notebook so you can **show clients before/after cleaning**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389eb96-1495-468a-809e-ff4c05297242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
